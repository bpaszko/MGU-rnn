{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import pretty_midi\n",
    "\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import deque, Counter\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/home/bartek/Datasets/maestro/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_path_to_pianoroll(path: str, fs: int=5) -> np.ndarray:\n",
    "    pmid = pretty_midi.PrettyMIDI(path)\n",
    "    piano = pmid.instruments[0]\n",
    "    pianoroll = piano.get_piano_roll(fs=fs)\n",
    "    return pianoroll\n",
    "    \n",
    "def pianoroll_to_time_dict(pianoroll: np.ndarray) -> Dict[int, str]:\n",
    "    times = np.unique(pianoroll.nonzero()[1])  # czasy gdzie występuje przynajmniej jedna nuta \n",
    "    index = pianoroll.nonzero()  # indeksy wszystkich nut\n",
    "    dict_keys_time = {}\n",
    "\n",
    "    for time in times:\n",
    "        index_where = (index[1] == time).nonzero()  # pozycje nut, które występują w danym czasie, w indeksie\n",
    "        notes = index[0][index_where]  # odszukanie nut\n",
    "        dict_keys_time[time] = ','.join(notes.astype(str))\n",
    "        \n",
    "    return dict_keys_time\n",
    "\n",
    "\n",
    "def piano_roll_to_pretty_midi(piano_roll, fs=100, program=0):\n",
    "    '''Convert a Piano Roll array into a PrettyMidi object\n",
    "     with a single instrument.\n",
    "    Parameters\n",
    "    ----------\n",
    "    piano_roll : np.ndarray, shape=(128,frames), dtype=int\n",
    "        Piano roll of one instrument\n",
    "    fs : int\n",
    "        Sampling frequency of the columns, i.e. each column is spaced apart\n",
    "        by ``1./fs`` seconds.\n",
    "    program : int\n",
    "        The program number of the instrument.\n",
    "    Returns\n",
    "    -------\n",
    "    midi_object : pretty_midi.PrettyMIDI\n",
    "        A pretty_midi.PrettyMIDI class instance describing\n",
    "        the piano roll.\n",
    "    '''\n",
    "    notes, frames = piano_roll.shape\n",
    "    pm = pretty_midi.PrettyMIDI()\n",
    "    instrument = pretty_midi.Instrument(program=program)\n",
    "\n",
    "    # pad 1 column of zeros so we can acknowledge inital and ending events\n",
    "    piano_roll = np.pad(piano_roll, [(0, 0), (1, 1)], 'constant')\n",
    "\n",
    "    # use changes in velocities to find note on / note off events\n",
    "    velocity_changes = np.nonzero(np.diff(piano_roll).T)\n",
    "\n",
    "    # keep track on velocities and note on times\n",
    "    prev_velocities = np.zeros(notes, dtype=int)\n",
    "    note_on_time = np.zeros(notes)\n",
    "\n",
    "    for time, note in zip(*velocity_changes):\n",
    "        # use time + 1 because of padding above\n",
    "        velocity = piano_roll[note, time + 1]\n",
    "        time = time / fs\n",
    "        if velocity > 0:\n",
    "            if prev_velocities[note] == 0:\n",
    "                note_on_time[note] = time\n",
    "                prev_velocities[note] = velocity\n",
    "        else:\n",
    "            pm_note = pretty_midi.Note(\n",
    "                velocity=prev_velocities[note],\n",
    "                pitch=note,\n",
    "                start=note_on_time[note],\n",
    "                end=time)\n",
    "            instrument.notes.append(pm_note)\n",
    "            prev_velocities[note] = 0\n",
    "    pm.instruments.append(instrument)\n",
    "    return pm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIDataset:\n",
    "    def __init__(self, converter, seq_len=50, song_batch_size=12, nn_batch_size=96):\n",
    "        self.converter = converter\n",
    "        self.seq_len = seq_len\n",
    "        self.song_batch_size = song_batch_size\n",
    "        self.nn_batch_size = nn_batch_size\n",
    "        self._pos = 0\n",
    "        self._song_batch = None\n",
    "        \n",
    "    def get_batch(self):\n",
    "        if self._song_batch is None:\n",
    "            songs_train, songs_target = self.converter.get_batch(self.song_batch_size, self.seq_len)\n",
    "            shuffle_order = np.random.permutation(np.arange(songs_target.shape[0]))\n",
    "            songs_train = songs_train[shuffle_order, :]\n",
    "            songs_target = songs_target[shuffle_order]\n",
    "            self._song_batch = (songs_train, songs_target)\n",
    "            self._pos = 0\n",
    "            \n",
    "        songs_train, songs_target = self._song_batch\n",
    "        end_pos = min(self._pos + self.nn_batch_size, songs_target.shape[0])\n",
    "        train_batch, target_batch = songs_train[self._pos:end_pos, :], songs_target[self._pos:end_pos]\n",
    "        if end_pos == songs_target.shape[0]:\n",
    "            self._song_batch = None\n",
    "        self._pos = end_pos\n",
    "        return train_batch, target_batch\n",
    "\n",
    "    def unique_notes(self):\n",
    "        return self.converter.unique_notes()\n",
    "    \n",
    "    def sample_start(self, n=1):\n",
    "        frequency = self.converter.notes_frequency()\n",
    "        notes = np.zeros(shape=self.seq_len)\n",
    "        for i in range(1,n+1):\n",
    "            notes[-i] = np.argmax(np.random.multinomial(1, frequency))\n",
    "        return notes\n",
    "    \n",
    "    def to_midi(self, sequence):\n",
    "        pianoroll = self.converter.sequence_to_pianoroll(sequence)\n",
    "        generate_to_midi = piano_roll_to_pretty_midi(pianoroll, fs=5)\n",
    "        for note in generate_to_midi.instruments[0].notes:\n",
    "            note.velocity = 100\n",
    "        return generate_to_midi\n",
    "        \n",
    "        \n",
    "class MIDIConverter:\n",
    "    def __init__(self, directory: str, frac: float=0.1) -> None:\n",
    "        assert 0 < frac <= 1\n",
    "        self._paths = self._locate_midi_files(directory, frac)\n",
    "        self._time_dicts, self._notes_mapping, self._notes_frequency = self._convert_to_time_dicts()\n",
    "        self._inverse_notes_mapping = {v: k for k, v in self._notes_mapping.items()}\n",
    "        \n",
    "    def get_batch(self, batch_size, seq_len):\n",
    "        idx = np.random.choice(len(self._paths), size=batch_size)\n",
    "        batch_train, batch_target = [], []\n",
    "        for i in idx:\n",
    "            time_dict = self._time_dicts[i]\n",
    "            train_vals, target_vals = self._time_dict_to_seq(time_dict, seq_len)\n",
    "            batch_train.append(train_vals)\n",
    "            batch_target.append(target_vals)\n",
    "        return np.vstack(batch_train), np.hstack(batch_target)\n",
    "        \n",
    "    def unique_notes(self):\n",
    "        return len(self._notes_mapping)\n",
    "    \n",
    "    def notes_frequency(self):\n",
    "        total = sum(self._notes_frequency.values())\n",
    "        freqs = np.zeros(shape=(len(self._notes_mapping) + 1), dtype=np.float64)\n",
    "        for note, idx in self._notes_frequency.items():\n",
    "            freqs[idx] = self._notes_frequency[note] / total\n",
    "        return freqs\n",
    "    \n",
    "    def sequence_to_pianoroll(self, sequence):\n",
    "        notes = [[int(note) for note in self._inverse_notes_mapping.get(idx, '-1').split(',')] for idx in sequence]\n",
    "        pianoroll = np.zeros(shape=(128, len(notes)))\n",
    "        for i, note_idx in enumerate(notes):\n",
    "            if note_idx != -1:\n",
    "                pianoroll[note_idx, i] = 1\n",
    "        return pianoroll\n",
    "        \n",
    "        \n",
    "    def _time_dict_to_seq(self, time_dict, seq_len) -> np.ndarray:\n",
    "        times = list(time_dict.keys())\n",
    "        start_time, end_time = np.min(times), np.max(times)\n",
    "        n_samples = end_time - start_time\n",
    "        initial_values = [0]*(seq_len-1) + [time_dict[start_time]]\n",
    "        train_values = np.zeros(shape=(n_samples+1, seq_len))\n",
    "        target_values = np.zeros(shape=(n_samples+1))\n",
    "        train_values_per_step = deque(initial_values)\n",
    "        for i in range(n_samples):\n",
    "            train_values[i, :] = list(train_values_per_step)\n",
    "            current_target = time_dict.get(start_time + i, 0)\n",
    "            target_values[i] = current_target\n",
    "            train_values_per_step.popleft()\n",
    "            train_values_per_step.append(current_target)\n",
    "        train_values[n_samples, :] = list(train_values_per_step)\n",
    "        return train_values, target_values\n",
    "        \n",
    "    def _convert_to_time_dicts(self) -> Tuple[Dict[int, Dict[int, str]], Dict[str, int]]:\n",
    "        unique_notes = list()\n",
    "        time_dicts = {}\n",
    "        for i, path in tqdm(enumerate(self._paths), total=len(self._paths)):\n",
    "            pianoroll = midi_path_to_pianoroll(path)\n",
    "            time_dict = pianoroll_to_time_dict(pianoroll)\n",
    "            time_dicts[i] = time_dict\n",
    "            unique_notes += list(time_dict.values())\n",
    "\n",
    "        notes_freq = Counter(unique_notes)\n",
    "        unique_notes = set(unique_notes)\n",
    "        # Replace strings with oridinal encoding\n",
    "        notes_mapping = {note:(i+1) for i, note in enumerate(unique_notes)}\n",
    "        for i, time_dict in time_dicts.items():\n",
    "            for time, notes in time_dict.items():\n",
    "                time_dict[time] = notes_mapping[notes]\n",
    "        return time_dicts, notes_mapping, notes_freq\n",
    "            \n",
    "    def _locate_midi_files(self, base_dir: str, frac: float) -> List[str]:\n",
    "        midi_files = []\n",
    "        for root, dirs, files in os.walk(base_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.midi'):\n",
    "                    midi_files.append(os.path.join(root, file))\n",
    "        return np.random.choice(midi_files, size=int(frac*len(midi_files)), replace=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af896ccf21e84d91ba8af65997cd54e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "converter = MIDIConverter('/home/bartek/Datasets/maestro/', frac=0.1)\n",
    "provider = MIDIDataset(converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, unique_notes, seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(unique_notes+1, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim * seq_len, unique_notes+1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _ = x.shape\n",
    "        embeds = self.embeddings(x)\n",
    "        lstm_out, _ = self.lstm(embeds.view(self.seq_len, batch_size, -1))\n",
    "        outputs = self.linear(lstm_out.view(batch_size, -1))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(embedding_dim=32, hidden_dim=128, unique_notes=provider.unique_notes(), seq_len=50)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, provider, length=50, temperature=1.0, device='cpu'):\n",
    "    notes = deque(provider.sample_start(1))\n",
    "    generated = [notes[-1]]\n",
    "    for i in range(length-1):\n",
    "        data = torch.tensor(data=np.expand_dims(np.array(notes), axis=0), dtype=torch.long).to(device)\n",
    "        output = F.softmax(model(data) / temperature, dim=1)\n",
    "        new_note = torch.multinomial(output, 1)[:, 0]\n",
    "        new_note = new_note.cpu().item()\n",
    "        notes.popleft()\n",
    "        notes.append(new_note)\n",
    "        generated.append(new_note)\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, provider, optimizer, criterion, iterations):\n",
    "    for iteration in tqdm(range(iterations)):\n",
    "        data, targets = provider.get_batch()\n",
    "        data, targets = torch.tensor(data=data, dtype=torch.long).to(device), torch.tensor(data=targets, dtype=torch.long).to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        target_preds = F.softmax(model(data))\n",
    "\n",
    "        loss = criterion(target_preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         sample = generate_sample(model, provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f75fb585e94c8eabb0680316c9043c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartek/Workspace/venvs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, provider, optimizer, loss, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = generate_sample(model, provider, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi = provider.to_midi(sample)\n",
    "midi.write('../music/hello.midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
